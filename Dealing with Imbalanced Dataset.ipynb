{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baf0f5f3",
   "metadata": {},
   "source": [
    "# Dealing with Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f681cebc",
   "metadata": {},
   "source": [
    "##About the DATA :\n",
    "we  have one of Brazil’s largest auto and homeowner insurance companies. The car insurance company’s claim predictions We challenged to build a model that predicts the probability that a driver will initiate an auto insurance claim in the next year. A more accurate prediction will allow them to further tailor their prices, and hopefully make auto insurance coverage more accessible to more drivers.raise the cost of insurance for good drivers and reduce the price for bad ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6738c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will load essential Libraries and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5e35e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "id                                                                              \n",
       "7        0          2              2          5              1              0   \n",
       "9        0          1              1          7              0              0   \n",
       "13       0          5              4          9              1              0   \n",
       "16       0          0              1          2              0              0   \n",
       "17       0          0              2          0              1              0   \n",
       "\n",
       "    ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ...  \\\n",
       "id                                                              ...   \n",
       "7               0              1              0              0  ...   \n",
       "9               0              0              1              0  ...   \n",
       "13              0              0              1              0  ...   \n",
       "16              1              0              0              0  ...   \n",
       "17              1              0              0              0  ...   \n",
       "\n",
       "    ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "id                                                                   \n",
       "7            9           1           5           8               0   \n",
       "9            3           1           1           9               0   \n",
       "13           4           2           7           7               0   \n",
       "16           2           2           4           9               0   \n",
       "17           3           1           1           3               0   \n",
       "\n",
       "    ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "id                                                                   \n",
       "7                1               1               0               0   \n",
       "9                1               1               0               1   \n",
       "13               1               1               0               1   \n",
       "16               0               0               0               0   \n",
       "17               0               0               1               1   \n",
       "\n",
       "    ps_calc_20_bin  \n",
       "id                  \n",
       "7                1  \n",
       "9                0  \n",
       "13               0  \n",
       "16               0  \n",
       "17               0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"A:\\coreco\\Smote\\train.csv\",index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f3f2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 595212 entries, 7 to 1488027\n",
      "Data columns (total 58 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   target          595212 non-null  int64  \n",
      " 1   ps_ind_01       595212 non-null  int64  \n",
      " 2   ps_ind_02_cat   595212 non-null  int64  \n",
      " 3   ps_ind_03       595212 non-null  int64  \n",
      " 4   ps_ind_04_cat   595212 non-null  int64  \n",
      " 5   ps_ind_05_cat   595212 non-null  int64  \n",
      " 6   ps_ind_06_bin   595212 non-null  int64  \n",
      " 7   ps_ind_07_bin   595212 non-null  int64  \n",
      " 8   ps_ind_08_bin   595212 non-null  int64  \n",
      " 9   ps_ind_09_bin   595212 non-null  int64  \n",
      " 10  ps_ind_10_bin   595212 non-null  int64  \n",
      " 11  ps_ind_11_bin   595212 non-null  int64  \n",
      " 12  ps_ind_12_bin   595212 non-null  int64  \n",
      " 13  ps_ind_13_bin   595212 non-null  int64  \n",
      " 14  ps_ind_14       595212 non-null  int64  \n",
      " 15  ps_ind_15       595212 non-null  int64  \n",
      " 16  ps_ind_16_bin   595212 non-null  int64  \n",
      " 17  ps_ind_17_bin   595212 non-null  int64  \n",
      " 18  ps_ind_18_bin   595212 non-null  int64  \n",
      " 19  ps_reg_01       595212 non-null  float64\n",
      " 20  ps_reg_02       595212 non-null  float64\n",
      " 21  ps_reg_03       595212 non-null  float64\n",
      " 22  ps_car_01_cat   595212 non-null  int64  \n",
      " 23  ps_car_02_cat   595212 non-null  int64  \n",
      " 24  ps_car_03_cat   595212 non-null  int64  \n",
      " 25  ps_car_04_cat   595212 non-null  int64  \n",
      " 26  ps_car_05_cat   595212 non-null  int64  \n",
      " 27  ps_car_06_cat   595212 non-null  int64  \n",
      " 28  ps_car_07_cat   595212 non-null  int64  \n",
      " 29  ps_car_08_cat   595212 non-null  int64  \n",
      " 30  ps_car_09_cat   595212 non-null  int64  \n",
      " 31  ps_car_10_cat   595212 non-null  int64  \n",
      " 32  ps_car_11_cat   595212 non-null  int64  \n",
      " 33  ps_car_11       595212 non-null  int64  \n",
      " 34  ps_car_12       595212 non-null  float64\n",
      " 35  ps_car_13       595212 non-null  float64\n",
      " 36  ps_car_14       595212 non-null  float64\n",
      " 37  ps_car_15       595212 non-null  float64\n",
      " 38  ps_calc_01      595212 non-null  float64\n",
      " 39  ps_calc_02      595212 non-null  float64\n",
      " 40  ps_calc_03      595212 non-null  float64\n",
      " 41  ps_calc_04      595212 non-null  int64  \n",
      " 42  ps_calc_05      595212 non-null  int64  \n",
      " 43  ps_calc_06      595212 non-null  int64  \n",
      " 44  ps_calc_07      595212 non-null  int64  \n",
      " 45  ps_calc_08      595212 non-null  int64  \n",
      " 46  ps_calc_09      595212 non-null  int64  \n",
      " 47  ps_calc_10      595212 non-null  int64  \n",
      " 48  ps_calc_11      595212 non-null  int64  \n",
      " 49  ps_calc_12      595212 non-null  int64  \n",
      " 50  ps_calc_13      595212 non-null  int64  \n",
      " 51  ps_calc_14      595212 non-null  int64  \n",
      " 52  ps_calc_15_bin  595212 non-null  int64  \n",
      " 53  ps_calc_16_bin  595212 non-null  int64  \n",
      " 54  ps_calc_17_bin  595212 non-null  int64  \n",
      " 55  ps_calc_18_bin  595212 non-null  int64  \n",
      " 56  ps_calc_19_bin  595212 non-null  int64  \n",
      " 57  ps_calc_20_bin  595212 non-null  int64  \n",
      "dtypes: float64(10), int64(48)\n",
      "memory usage: 267.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1975cc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target            0\n",
       "ps_ind_01         0\n",
       "ps_ind_02_cat     0\n",
       "ps_ind_03         0\n",
       "ps_ind_04_cat     0\n",
       "ps_ind_05_cat     0\n",
       "ps_ind_06_bin     0\n",
       "ps_ind_07_bin     0\n",
       "ps_ind_08_bin     0\n",
       "ps_ind_09_bin     0\n",
       "ps_ind_10_bin     0\n",
       "ps_ind_11_bin     0\n",
       "ps_ind_12_bin     0\n",
       "ps_ind_13_bin     0\n",
       "ps_ind_14         0\n",
       "ps_ind_15         0\n",
       "ps_ind_16_bin     0\n",
       "ps_ind_17_bin     0\n",
       "ps_ind_18_bin     0\n",
       "ps_reg_01         0\n",
       "ps_reg_02         0\n",
       "ps_reg_03         0\n",
       "ps_car_01_cat     0\n",
       "ps_car_02_cat     0\n",
       "ps_car_03_cat     0\n",
       "ps_car_04_cat     0\n",
       "ps_car_05_cat     0\n",
       "ps_car_06_cat     0\n",
       "ps_car_07_cat     0\n",
       "ps_car_08_cat     0\n",
       "ps_car_09_cat     0\n",
       "ps_car_10_cat     0\n",
       "ps_car_11_cat     0\n",
       "ps_car_11         0\n",
       "ps_car_12         0\n",
       "ps_car_13         0\n",
       "ps_car_14         0\n",
       "ps_car_15         0\n",
       "ps_calc_01        0\n",
       "ps_calc_02        0\n",
       "ps_calc_03        0\n",
       "ps_calc_04        0\n",
       "ps_calc_05        0\n",
       "ps_calc_06        0\n",
       "ps_calc_07        0\n",
       "ps_calc_08        0\n",
       "ps_calc_09        0\n",
       "ps_calc_10        0\n",
       "ps_calc_11        0\n",
       "ps_calc_12        0\n",
       "ps_calc_13        0\n",
       "ps_calc_14        0\n",
       "ps_calc_15_bin    0\n",
       "ps_calc_16_bin    0\n",
       "ps_calc_17_bin    0\n",
       "ps_calc_18_bin    0\n",
       "ps_calc_19_bin    0\n",
       "ps_calc_20_bin    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb49619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 58)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d7bfb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n",
       "       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n",
       "       'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin',\n",
       "       'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n",
       "       'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n",
       "       'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n",
       "       'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n",
       "       'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n",
       "       'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n",
       "       'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n",
       "       'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n",
       "       'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n",
       "       'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n",
       "       'ps_calc_20_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "653189de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.036448</td>\n",
       "      <td>1.900378</td>\n",
       "      <td>1.358943</td>\n",
       "      <td>4.423318</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>0.393742</td>\n",
       "      <td>0.257033</td>\n",
       "      <td>0.163921</td>\n",
       "      <td>0.185304</td>\n",
       "      <td>...</td>\n",
       "      <td>5.441382</td>\n",
       "      <td>1.441918</td>\n",
       "      <td>2.872288</td>\n",
       "      <td>7.539026</td>\n",
       "      <td>0.122427</td>\n",
       "      <td>0.627840</td>\n",
       "      <td>0.554182</td>\n",
       "      <td>0.287182</td>\n",
       "      <td>0.349024</td>\n",
       "      <td>0.153318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.187401</td>\n",
       "      <td>1.983789</td>\n",
       "      <td>0.664594</td>\n",
       "      <td>2.699902</td>\n",
       "      <td>0.493311</td>\n",
       "      <td>1.350642</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.370205</td>\n",
       "      <td>0.388544</td>\n",
       "      <td>...</td>\n",
       "      <td>2.332871</td>\n",
       "      <td>1.202963</td>\n",
       "      <td>1.694887</td>\n",
       "      <td>2.746652</td>\n",
       "      <td>0.327779</td>\n",
       "      <td>0.483381</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>0.452447</td>\n",
       "      <td>0.476662</td>\n",
       "      <td>0.360295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target      ps_ind_01  ps_ind_02_cat      ps_ind_03  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.036448       1.900378       1.358943       4.423318   \n",
       "std         0.187401       1.983789       0.664594       2.699902   \n",
       "min         0.000000       0.000000      -1.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       2.000000   \n",
       "50%         0.000000       1.000000       1.000000       4.000000   \n",
       "75%         0.000000       3.000000       2.000000       6.000000   \n",
       "max         1.000000       7.000000       4.000000      11.000000   \n",
       "\n",
       "       ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.416794       0.405188       0.393742       0.257033   \n",
       "std         0.493311       1.350642       0.488579       0.436998   \n",
       "min        -1.000000      -1.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       1.000000       1.000000   \n",
       "max         1.000000       6.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_08_bin  ps_ind_09_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  595212.000000  595212.000000  ...  595212.000000  595212.000000   \n",
       "mean        0.163921       0.185304  ...       5.441382       1.441918   \n",
       "std         0.370205       0.388544  ...       2.332871       1.202963   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      19.000000      10.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  595212.000000  595212.000000   595212.000000   595212.000000   \n",
       "mean        2.872288       7.539026        0.122427        0.627840   \n",
       "std         1.694887       2.746652        0.327779        0.483381   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      23.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   595212.000000   595212.000000   595212.000000   595212.000000  \n",
       "mean         0.554182        0.287182        0.349024        0.153318  \n",
       "std          0.497056        0.452447        0.476662        0.360295  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4595d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 573518\n",
      "Class 1: 21694\n",
      "Proportion: 26.44 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we will visualise the target column\n",
    "target_count = df.target.value_counts()\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "\n",
    "target_count.plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e33d0fa4",
   "metadata": {},
   "source": [
    "1)There are no null values .\n",
    "2)There are 58 columns alomg with Target column\n",
    "3)There are 595212 rows in data.\n",
    "4)We clearly see that data is highly imbalanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e789a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will build model before applying scaling\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67ff8f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X ,y, test_size=0.2 ,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "02b0df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8412958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9999\n",
      "- F1 score: 0.9999\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9984\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9632\n",
      "- F1 score: 0.9451\n",
      "- Precision: 0.0000\n",
      "- Recall: 0.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9636\n",
      "- F1 score: 0.9458\n",
      "- Precision: 0.0000\n",
      "- Recall: 0.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9632\n",
      "- F1 score: 0.9451\n",
      "- Precision: 0.0000\n",
      "- Recall: 0.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9640\n",
      "- F1 score: 0.9467\n",
      "- Precision: 0.9940\n",
      "- Recall: 0.0095\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9631\n",
      "- F1 score: 0.9451\n",
      "- Precision: 0.3000\n",
      "- Recall: 0.0007\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),    \n",
    "    \"XGBClassifier\": XGBClassifier()        \n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "    model_train_precision = precision_score(y_train, y_train_pred) # Calculate Precision\n",
    "    model_train_recall = recall_score(y_train, y_train_pred) # Calculate Recall\n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "    model_test_precision = precision_score(y_test, y_test_pred) # Calculate Precision\n",
    "    model_test_recall = recall_score(y_test, y_test_pred) # Calculate Recall\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "453ef40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.31%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "da3c8193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of imbalance: 3.78%\n"
     ]
    }
   ],
   "source": [
    "minority_class_count = target_counts.min()\n",
    "majority_class_count = target_counts.max()\n",
    "imbalance_percentage = (minority_class_count / majority_class_count) * 100.0\n",
    "\n",
    "print(\"Percentage of imbalance: %.2f%%\" % imbalance_percentage)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42a0f94e",
   "metadata": {},
   "source": [
    "A)\n",
    "Here we see that the accuracy of our xgboost model  befor e wwe do smoe scaling is ,\n",
    "Accuracy: 96.31%\n",
    "B)\n",
    "the proportion oof our minority class is 3.7% that of Majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224bbd4",
   "metadata": {},
   "source": [
    "# we will apply some resampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6b56a6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\geeta\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\geeta\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\geeta\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\geeta\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\geeta\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.24.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\geeta\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "80b087fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fe6ed9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "13ee64ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "0    0.963649\n",
      "1    0.036351\n",
      "Name: target, dtype: float64\n",
      "\n",
      "Class distribution after SMOTE:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_smote_scaled = scaler.fit_transform(X_train_smote)\n",
    "\n",
    "# Calculate class distributions before and after SMOTE\n",
    "print(\"Original class distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print()\n",
    "\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_smote).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c416ff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9999\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9611\n",
      "- F1 score: 0.9443\n",
      "- Precision: 0.0542\n",
      "- Recall: 0.0034\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8755\n",
      "- F1 score: 0.9018\n",
      "- Precision: 0.0449\n",
      "- Recall: 0.1196\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8753\n",
      "- F1 score: 0.9011\n",
      "- Precision: 0.0435\n",
      "- Recall: 0.1138\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9638\n",
      "- F1 score: 0.9462\n",
      "- Precision: 0.8831\n",
      "- Recall: 0.0039\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9631\n",
      "- F1 score: 0.9451\n",
      "- Precision: 0.2000\n",
      "- Recall: 0.0007\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),    \n",
    "    \"XGBClassifier\": XGBClassifier()        \n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train_smote, y_train_smote) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Training set performance\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "    model_train_precision = precision_score(y_train, y_train_pred) # Calculate Precision\n",
    "    model_train_recall = recall_score(y_train, y_train_pred) # Calculate Recall\n",
    "\n",
    "\n",
    "    # Test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "    model_test_precision = precision_score(y_test, y_test_pred) # Calculate Precision\n",
    "    model_test_recall = recall_score(y_test, y_test_pred) # Calculate Recall\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "    \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0e65ccf",
   "metadata": {},
   "source": [
    "Findings :  here we can not consider accuraccy as it can be misleading and gives high value due to imbalance\n",
    "1)Random Forest:\n",
    "Before SMOTE: Achieves very high accuracy and performance metrics on the training set, but struggles with recall on the    test set which means it struggles in correctly identifying instances of the minority class.\n",
    "After SMOTE: Training set performance remains excellent, but there's a slight improvement in recall on the test set after SMOTE, suggesting that the model is now better at identifying minority class instances, although still not optimal.\n",
    "\n",
    "2)Logistic Regression:\n",
    "Before SMOTE: very poor performance  with low recall on the test set.\n",
    "After SMOTE: A slight improvement in recall and precision, indicating that Logistic Regression may not handle class imbalance well without proper techniques like SMOTE.\n",
    "\n",
    "3)XGBClassifier:\n",
    "Before SMOTE: Achieves good accuracy and precision but struggles with recall on the test set.\n",
    "After SMOTE: Performance on the test set remains similar, with slight improvements in precision and recall, suggesting that SMOTE has a limited effect on improving model performance.\n",
    "##more unserstanding of underlying data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5af7bd6f",
   "metadata": {},
   "source": [
    "Another ways to handle imbalancedata\n",
    "\n",
    " We are going to aplly Under Sampling and Over sampling Methods for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3507d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3197f90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "0    0.963649\n",
      "1    0.036351\n",
      "Name: target, dtype: float64\n",
      "\n",
      "Class distribution after undersampling:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: target, dtype: float64\n",
      "\n",
      "Class distribution after oversampling:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)        # undersampling\n",
    "X_train_undersampled, y_train_undersampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)         #  oversampling\n",
    "X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_undersampled_scaled = scaler.fit_transform(X_train_undersampled)\n",
    "X_train_oversampled_scaled = scaler.fit_transform(X_train_oversampled)\n",
    "\n",
    "\n",
    "print(\"Original class distribution:\")                 # Calculate class distributions before and after\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print()\n",
    "\n",
    "print(\"Class distribution after undersampling:\")\n",
    "print(pd.Series(y_train_undersampled).value_counts(normalize=True))\n",
    "print()\n",
    "\n",
    "print(\"Class distribution after oversampling:\")\n",
    "print(pd.Series(y_train_oversampled).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "756f8695",
   "metadata": {},
   "source": [
    "i)Under Sampling:\n",
    "     Randon UnderSampler :\n",
    "     We are removing samples Randomly from Major Class to make balance eith minority Class\n",
    " ii)Oversampling:\n",
    "     Randon OverSampler :\n",
    "     We are duplicating samples from Minority class randomly\n",
    "Apply  StandardScaler to original and resampled datasets for standardizing data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57d02bed",
   "metadata": {},
   "source": [
    "if we want to remove outliers then you can do it on undersampling not on Oversampling methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
